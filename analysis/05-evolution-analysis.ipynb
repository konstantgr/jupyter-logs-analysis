{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from analysis.dataset.june_dataset import JuNEDataset\n",
    "from analysis.metrics.metrics_cells import CellsMetrics\n",
    "\n",
    "\n",
    "def read_config(config_path: Path = Path(\"data_config.yaml\")) -> dict:\n",
    "    with config_path.open(\"r\") as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError:\n",
    "            return {}\n",
    "\n",
    "config = read_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hack = pd.read_csv(config.get(\"dataset_path\"), index_col=0)\n",
    "df_labels = pd.read_csv(config.get(\"label_mapping_path\"), index_col=0)\n",
    "df_hack = df_hack.merge(df_labels, on='action_id')\n",
    "\n",
    "df_hack.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "june = JuNEDataset(df_hack)\n",
    "june.prepare_dataset()\n",
    "june.df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evolution_df = june.to_evolution_dataframe()\n",
    "evolution_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evolution_df.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = (\n",
    "    evolution_df.event.isin([\"execute\", \"create\", \"delete\", \"rendered\"])\n",
    ")\n",
    "evolution_df[mask].head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processor = CellsMetrics()\n",
    "\n",
    "df_tmp = evolution_df[mask]\n",
    "df_tmp['event'] = 'execute'\n",
    "\n",
    "df_analysis = processor.calculate_cell_metrics(df_tmp.iloc[:])\n",
    "df_analysis.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def continuous_transform(x, y, size: int = 1000, normalize: bool = True) -> tuple[np.ndarray, np.ndarray]:\n",
    "    x_max = 1 if normalize else np.max(x)\n",
    "    xp = np.linspace(0, x_max, size)\n",
    "    x = np.linspace(0, x_max, len(y))\n",
    "    y = np.array(y)\n",
    "\n",
    "    y[np.isnan(y)] = 0\n",
    "    y = np.interp(xp, x, y) + 1e-5\n",
    "    return xp, y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.reset_orig()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('https://github.com/klieret/simple-science-style/raw/main/stylesheets/sss1.mplstyle')\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "metric_name = 'ccn'\n",
    "aggregation_function = 'sum'\n",
    "task_ax_mapping = {'task1': ax1, 'task2': ax2}\n",
    "mean_curve = {'task1': [], 'task2': []}\n",
    "\n",
    "df = df_analysis\n",
    "df = df[df.comments <= df.comments.quantile(0.95)]\n",
    "\n",
    "size_threshold = 200\n",
    "mn, mx = np.inf, -np.inf\n",
    "for (task, kernel_id), g in df.groupby(['task', 'kernel_id']):\n",
    "    if g.shape[0] < size_threshold:\n",
    "        continue\n",
    "    events_count = g.state_num.unique().shape[0]\n",
    "    if metric_name == \"cells_num\":\n",
    "        agg_fun_values = g.groupby(\"state_num\").cell_index.agg('count')\n",
    "        if agg_fun_values.iloc[:3].max() > 10:\n",
    "            continue\n",
    "    else:\n",
    "        agg_fun_values = g.groupby(\"state_num\")[metric_name].agg(aggregation_function)\n",
    "        \n",
    "    # if agg_fun_values.iloc[:3].max() > 10:\n",
    "    #     continue\n",
    "\n",
    "    x, y = continuous_transform(\n",
    "        np.arange(events_count), agg_fun_values,\n",
    "        normalize=True\n",
    "    )\n",
    "    mean_curve[task].append(y)\n",
    "\n",
    "    mn = y.min() if y.min() < mn else mn\n",
    "    mx = y.max() if y.max() > mx else mx\n",
    "\n",
    "    task_ax_mapping[task].plot(x, y, color='k', alpha=0.2)\n",
    "\n",
    "for task, curves in mean_curve.items():\n",
    "    y = np.sum(curves, axis=0) / len(curves)\n",
    "    x = np.linspace(0, 1, len(y))\n",
    "\n",
    "    task_ax_mapping[task].axhline(y[-1], color='k', ls=(0, (5, 5)))\n",
    "    task_ax_mapping[task].plot(x, y, color='firebrick', lw=3)\n",
    "\n",
    "for task, ax in task_ax_mapping.items():\n",
    "    ax.set_ylim(mn * 0.9, mx * 1.1)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xlabel('Normalized Time', fontsize=14)\n",
    "    ax.set_ylabel(f\"{metric_name} ({aggregation_function})\", fontsize=14)\n",
    "    ax.set_title(task.replace(\"_\", \" \"), fontsize=14)\n",
    "    ax.grid(False)\n",
    "\n",
    "\n",
    "ax2.set_ylabel(None)\n",
    "ax2.set_yticklabels([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/evolution/{metric_name}_{aggregation_function}_tasks.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "df_tmp = df.groupby(['kernel_id', 'state_num'])[['sloc', 'ccn', 'objects']] \\\n",
    "    .agg(['mean', 'sum']).reset_index()\n",
    "\n",
    "df_tmp = df_tmp.loc[df_tmp.groupby('kernel_id').state_num.idxmax()].set_index(\"kernel_id\")\n",
    "df_tmp['task'] = df_analysis[['task', 'kernel_id']] \\\n",
    "    .drop_duplicates(keep='last').set_index('kernel_id')['task']\n",
    "\n",
    "df_tmp['expert'] = june.df[['expert', 'kernel_id']] \\\n",
    "    .drop_duplicates(keep='last').set_index('kernel_id')['expert']\n",
    "\n",
    "df_tmp = df_tmp.reset_index()\n",
    "\n",
    "cols = list(itertools.product(['sloc', 'ccn', 'objects'], ['mean', 'sum'], ['mean']))\n",
    "table = df_tmp.drop('state_num', axis=1).groupby([\"task\", \"expert\"]).describe().loc[:, cols]\n",
    "table.round(2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(table.round(2).applymap('{:.2f}'.format).to_latex(escape=True, multirow=True))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tmp = df_analysis.groupby(['kernel_id', 'state_num'])[['sloc', 'ccn', 'objects']] \\\n",
    "    .agg(['mean', 'sum']).reset_index()\n",
    "df_tmp.columns = ['_'.join(col).strip(\"_\") for col in df_tmp.columns.values]\n",
    "\n",
    "df_tmp = pd.merge(\n",
    "    df_tmp,\n",
    "    df_analysis[['task', 'kernel_id']] \\\n",
    "        .drop_duplicates(keep='last')[['kernel_id', 'task']],\n",
    "    on='kernel_id'\n",
    ")\n",
    "\n",
    "df_tmp = pd.merge(\n",
    "    df_tmp,\n",
    "    june.df[['expert', 'kernel_id']] \\\n",
    "        .drop_duplicates(keep='last')[['kernel_id', 'expert']],\n",
    "    on='kernel_id'\n",
    ")\n",
    "\n",
    "max_values = df_tmp.groupby('kernel_id')['state_num'].transform('max')\n",
    "df_tmp['normalized_state'] = df_tmp['state_num'] / max_values\n",
    "\n",
    "metrics_list = list(df_tmp)[2:-3]\n",
    "\n",
    "df_corr = df_tmp.groupby(['task', 'expert'])[['normalized_state', *metrics_list]].corr()\n",
    "indices = [i for i in df_corr.index if i[-1] == 'normalized_state']\n",
    "df_corr[metrics_list] = df_corr[metrics_list]\n",
    "\n",
    "table = df_corr.loc[indices][metrics_list]\n",
    "table.round(3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table.columns = pd.MultiIndex.from_tuples([tuple(i.split('_')) for i in table.columns.to_list()])\n",
    "table = table.reset_index().drop(columns='level_2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pretty_lang = {'task1': 'DS', 'task2': 'ML', np.NaN: 'All',\n",
    "               False: 'Student', True: 'Professional'}\n",
    "new_names = ['Task','Level of expertise', 'SLOC', 'SLOC', 'CCN', 'CCN', 'N of objects', 'N of objects']\n",
    "table.columns =  pd.MultiIndex.from_tuples([(new_names[i] ,column[1]) for i, column in enumerate(table.columns.to_list())])\n",
    "table = table.replace(pretty_lang).set_index(['Task', 'Level of expertise']).applymap(lambda x: str.format(\"{:0_.2f}\", x).replace('.', ',').replace('_', '.'))\n",
    "print(table.to_latex(escape=True, multirow=True))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "alpha = 0.05\n",
    "for task in ['task1', 'task2']:\n",
    "    for expert in [True, False]:\n",
    "        for metric in metrics_list:\n",
    "            df_sample = df_tmp[(df_tmp.task == task) & (df_tmp.expert == expert)][['normalized_state', metric]]\n",
    "            cor = pg.corr(df_sample.normalized_state, df_sample[metric])\n",
    "            if cor['p-val'].iloc[0] > alpha:\n",
    "                print(metric, task, expert, cor['r'].iloc[0].round(2), cor['p-val'].iloc[0].round(2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
