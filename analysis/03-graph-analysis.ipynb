{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Packages Loading\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from analysis.dataset.june_dataset import JuNEDataset\n",
    "from analysis.metrics.metrics_graph import GraphMetrics\n",
    "from analysis.metrics.utils.graph_tools import dataframe_to_graphviz\n",
    "\n",
    "\n",
    "def read_config(config_path: Path = Path(\"data_config.yaml\")) -> dict:\n",
    "    with config_path.open(\"r\") as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError:\n",
    "            return {}\n",
    "\n",
    "\n",
    "config = read_config()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_hack = pd.read_csv(config.get(\"dataset_path\"), index_col=0)\n",
    "df_labels = pd.read_csv(config.get(\"label_mapping_path\"), index_col=0)\n",
    "df_hack = df_hack.merge(df_labels, on='action_id')\n",
    "\n",
    "df_hack.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "june = JuNEDataset(df_hack)\n",
    "june.prepare_dataset()\n",
    "june.df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialize Metrics Processor\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processor = GraphMetrics()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics Calculation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped = june.df.groupby(\"kernel_id\")\n",
    "df_kernel = grouped.get_group(list(grouped.groups.keys())[0])\n",
    "df_kernel.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_metrics = processor.calculate_kernel_metrics(df_kernel)\n",
    "graph_metrics.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_metrics = processor.calculate_metrics(june.df)\n",
    "graph_metrics.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tmp = june.df[['user_id', 'kernel_id', 'expert', 'task']] \\\n",
    "    .drop_duplicates(subset=['user_id', 'kernel_id', 'expert'], keep='last')\n",
    "\n",
    "graph_metrics_merged = graph_metrics.merge(df_tmp, on='kernel_id')\n",
    "graph_metrics_merged.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = list(processor.graph_metrics_mapping.keys())\n",
    "graph_table = graph_metrics_merged.groupby(['task', 'expert'])[metrics].mean().round(2).applymap('{:.2f}'.format)\n",
    "graph_table\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pretty_lang = {'task1': 'DS', 'task2': 'ML', np.NaN: 'All',\n",
    "               False: 'Student', True: 'Professional'}\n",
    "\n",
    "new_names = ['Task','Level of expertise', 'Modularity', 'Average degree', 'Average clustering coef.']\n",
    "graph_table = graph_table.reset_index()\n",
    "graph_table.columns = new_names\n",
    "graph_table = graph_table.replace(pretty_lang).set_index(['Task', 'Level of expertise']).astype(float).applymap(lambda x: str.format(\"{:0_.2f}\", x).replace('.', ',').replace('_', '.'))\n",
    "print(graph_table.to_latex(escape=True))\n",
    "\n",
    "# print(graph_table.to_latex(escape=True, multirow=True))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_table.replace(pretty_lang).set_index(['Task', 'Level of expertise']).astype(float).applymap(lambda x: str.format(\"{:0_.2f}\", x).replace('.', ',').replace('_', '.'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_metrics_merged.anova(dv=\"modularity\", between=[\"expert\", \"task\"]).round(3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_metrics_merged.anova(dv=\"average_degree\", between=[\"expert\", \"task\"]).round(3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_metrics_merged.anova(dv=\"average_clustering\", between=[\"expert\", \"task\"]).round(3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Display graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphs = {}\n",
    "grouped = june.df.groupby(['user_id', 'kernel_id'])\n",
    "\n",
    "for (user_id, kernel_id), g in tqdm(grouped):\n",
    "    df_kernel = g\n",
    "    gv = dataframe_to_graphviz(df_kernel)\n",
    "    gv.attr(rankdir='LR', size='100,100')\n",
    "    gv.render(directory='figures/graphs', format='png', filename=f\"graph_{user_id}\", cleanup=True).replace('\\\\', '/')\n",
    "    graphs[(user_id, kernel_id)] = gv\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(graphs.values())[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped = june.df.groupby(\"kernel_id\")\n",
    "\n",
    "load = True\n",
    "if not load:\n",
    "    evolution_dfs = [\n",
    "        pd.concat(\n",
    "            [processor.calculate_metrics(g.iloc[:i], progress=False)\n",
    "             for i in tqdm(range(1, g.shape[0], 10))], axis=0, ignore_index=True\n",
    "        ).reset_index().rename({\"index\": \"state_num\"}, axis=1)\n",
    "        for kernel_id, g in grouped\n",
    "    ]\n",
    "\n",
    "    all_evolutions = pd.concat(evolution_dfs, axis=0, ignore_index=True)\n",
    "    all_evolutions.to_csv(\"../data/graph_evolution_distill.csv\")\n",
    "else:\n",
    "    all_evolutions = pd.read_csv(config.get(\"graph_evolution_path\"), index_col=0)\n",
    "\n",
    "all_evolutions.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def continuous_transform(x, y, size: int = 1000, normalize: bool = True) -> tuple[np.ndarray, np.ndarray]:\n",
    "    x_max = 1 if normalize else np.max(x)\n",
    "    xp = np.linspace(0, x_max, size)\n",
    "    x = np.linspace(0, x_max, len(y))\n",
    "    y = np.array(y)\n",
    "\n",
    "    y[np.isnan(y)] = 0\n",
    "    y = np.interp(xp, x, y) + 1e-5\n",
    "    return xp, y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.reset_orig()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use('https://github.com/klieret/simple-science-style/raw/main/stylesheets/sss1.mplstyle')\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 2))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axs[i]\n",
    "    curves = []\n",
    "    for kernel_id, g in all_evolutions.groupby(\"kernel_id\"):\n",
    "        x, y = continuous_transform(\n",
    "            np.linspace(0, 1, g[metric].shape[0]),\n",
    "            g[metric]\n",
    "        )\n",
    "        curves.append(y)\n",
    "        ax.plot(x, y, alpha=0.2, color='k')\n",
    "\n",
    "    ax.set_title(metric, fontsize=14)\n",
    "    ax.plot(x, np.sum(curves, axis=0) / len(curves), color='firebrick', lw=4)\n",
    "\n",
    "axs[1].set_xlabel(\"Normalized time\", fontsize=14)\n",
    "axs[1].set_yscale(\"log\")\n",
    "plt.savefig(\"figures/evolution/graph_metrics.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tmp = june.df[['user_id', 'kernel_id', 'expert', 'task']] \\\n",
    "    .drop_duplicates(subset=['user_id', 'kernel_id', 'expert'], keep='last')\n",
    "\n",
    "graph_evolution_merged = all_evolutions.merge(df_tmp, on='kernel_id')\n",
    "graph_evolution_merged.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_tmp = graph_evolution_merged\n",
    "max_values = df_tmp.groupby('kernel_id')['state_num'].transform('max')\n",
    "df_tmp['normalized_state'] = df_tmp['state_num'] / max_values\n",
    "\n",
    "df_corr = df_tmp.groupby(['task', 'expert'])[['normalized_state', *metrics]].corr()\n",
    "indices = [i for i in df_corr.index if i[-1] == 'normalized_state']\n",
    "df_corr[metrics] = df_corr[metrics]\n",
    "\n",
    "table = df_corr.loc[indices][metrics].droplevel(2)\n",
    "table.round(3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(table.round(2).applymap('{:.2f}'.format).to_latex(escape=True, multirow=True))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "for task in ['task1', 'task2']:\n",
    "    for expert in [True, False]:\n",
    "        for metric in metrics:\n",
    "            df_sample = df_tmp[(df_tmp.task == task) & (df_tmp.expert == expert)][['normalized_state', metric]]\n",
    "            cor = pg.corr(df_sample.normalized_state, df_sample[metric])\n",
    "            if cor['p-val'].iloc[0] > alpha:\n",
    "                print(metric, task, expert, cor['r'].iloc[0].round(2), cor['p-val'].iloc[0].round(2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
